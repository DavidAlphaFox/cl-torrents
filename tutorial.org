
* Step 1 - first start

Scraping   The   Pirate   Bay   is    easy,   they   don't   rely   on
javascript-generated pages. We just have to:

- get the html page ([[http://quickdocs.org/dexador/][dexador]]: =(dex:get <url>)=)
- parse the html into a data structure ([[https://shinmera.github.io/plump/][plump]]: =(plump:parse <html>)=)
- search   with  CSS   selectors  ([[https://shinmera.github.io/lquery][lquery]]:   =(lquery:"  <parsed-html>
  <selectors>)=)

Let's go.

Install our dependencies right away:

#+BEGIN_EXPORT latex
(ql:quickload '("dexador" "plump" "lquery"))
#+END_EXPORT

To begin  with, we do  a search on the  website and we  copy-paste the
url. We get one like this:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr=matrix&ID=&Limit=800&Letter=&Sorting=DSeeder"
    "the url to search matrix.")
#+END_SRC

It has our search term in it (=matrix=) along with url parameters.

It also sorts the results by number of seeders for us :) (=&Sorting=DSeeder=).

We will use CSS selectors to extract information from the web page, so
we can use  our browser's developer tools to inspect  the structure of
the page  and guess our  selectors: right  click on a  result's title,
choose "inspect element". It highlights some html similar to this:

#+BEGIN_SRC html
  <td class="Title">
    <span class="ColorA">
      <a href="https://piratebay.to/torrent/1922147/Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438/" onclick="Javascript:OpenDetailPage('https://piratebay.to/torrent/1922147/Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438/'); return false;">Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438 </a>
    </span>
    <br>
      <span class="ColorB VaA">Upload Date: 20.02.15 </span>
      <span class="ColorB VaA">Size: 796,86 MB </span>
      <span class="ColorB"> </span>
  </td>
#+END_SRC


The title is  well delimited so we'll start selecting  our elements by
the CSS class =Title=, which gives:

#+BEGIN_SRC lisp
(defparameter *selectors* ".Title")
#+END_SRC

If  you are  not accostumed  to CSS  selectors, I  like this  webpage:
https://codingsec.net/2016/12/select-specific-text-css-using-selectors/.

** Trying out at the REPL

Let's try in the REPL:

#+BEGIN_SRC lisp
(defparameter html (dex:get *search-url*)) ;; returns the html
(defparameter parsed (plump:parse html))   ;; returns a list of plump elements
(defparameter results (lquery:$ parsed *selectors*)) ;; returns a list of stuff
(setf results (lquery:$ parsed *selectors* (text)))  ;; returns text, i.e. the titles
#+END_SRC

A little explanation for the =lquery=  line: the last =(text)= part is
an lquery thing to get the text representation of the node, instead of
a lquery internal object.

I  like to  check the  html content  of the  plump nodes.  We use  the
=serialize= plump function (the second function from the doc ;) ):

#+BEGIN_SRC lisp
CL-TORRENTS> (plump:serialize (first results))
#+END_SRC

and BAM, error:

#+BEGIN_QUOTE
The value #(
... all the content of results here ...
)
is not of type LIST
…
#+END_QUOTE

pfff. Sorry for  this inconvenience. Indeed, lquery  returns a vector,
not a list (we  can see that with =#()= that denotes  a vector), so we
can not use =first= but have to use =(aref <vector> 0)= instead, or we
have to =coerce= the result to a list.

Personnally  I find  this stupid  and frustrating,  particularly being
used in Python  to access lots of data structures  in the same manner.
If    you    feel    like    fixing   this,    have    a    look    at
[CL21](https://lispcookbook.github.io/cl-cookbook/cl21.html),  "Common
Lisp for  the 21st century"  which, amongst other  features, redefines
some  functions to  make them  generic (that  work on  lists, vectors,
hashmaps,…). CL21  is a CL library,  meaning we can of  course use the
others CL libraries with  it, or that we can use  cl21 alongside CL in
only in some places but not in all our project (like in only one file,
one "package"). I  chose to not present you this  lib at the beginning
but I might do so later on.

Allright so, back to printing the html content of our first result:

#+BEGIN_SRC text
CL-TORRENTS> (plump:serialize (aref results 0))
<th class="Title header ">
<a href="https://piratebay.to/search/0/800/0/matrix/0/ATitle/1/">Title</a>
</th>
">"
#+END_SRC

gosh, there  is not much in  it.  I was  too quick in defining  my CSS
selector.  This  first result should  not be catched by  our selector,
because it is not a link to a torrent but only the header of the table
(see "Title header" and the =th= ?).

But that's not  all. I also want  to scrape the number  of seeders and
leechers and  the =.Title= selector  doesn't include them  (this I see
with the browser's web inspector). If I select the including =tr= I'll
get all the data,  and I must ensure to select  those =tr= from inside
the body  of the table,  =tbody=.  So I'll  use a first  selector that
will return a list of elements of the table:

#+BEGIN_SRC lisp
(setf *selectors* "tbody tr")
#+END_SRC

and then for each result I'll get the title and the number of seeders.

So I can scrape again my search results with the new selector:

#+BEGIN_SRC lisp
(setf results (lquery:$ parsed *selectors* (text)))
#+END_SRC

this should print interesting stuff, like our torrents titles and even
strings like =S: 16L: 1= which are indeed our seeders and leechers.

I check the html content:

#+BEGIN_SRC lisp
  CL-TORRENTS> (plump:serialize (aref res 0))
  ;todo: insert here html content with seeders too.
#+END_SRC

allright, good. It has the link  to the torrent's page inside the href
of the "a" element, as well as the seeders count.

Note that we  can also inspect the results with  the mouse: left/right
clicks  on the  elements printed  in the  REPL get  us into  the Slime
inspector.

** Putting it together in a function

We came up with this function:

#+BEGIN_SRC lisp
(defun torrents (words)
  ""
  (let* ((html (dex:get *search-url*))
         (parsed (plump:parse html))
         (res (lquery:$ parsed *selectors* (text))))
    res))
#+END_SRC

and if  you prefer a  threading macro /  pipes, no problem,  but we'll
load another external library:

#+BEGIN_EXPORT latex
(ql:quickload "cl-arrows")
;; and we import its symbols:
(use-package "cl-arrows")
#+END_EXPORT

#+BEGIN_SRC lisp
(-<>> *search-url*
  (dex:get)
  (plump:parse)
  (lquery:$ <> *selectors* (text)))
#+END_SRC

[[https://github.com/nightfly19/cl-arrows][cl-arrows]] defines  a few  threading macros. The  classic one  would be
=->=,  which inserts  the  result  of the  preceding  form as  _first_
argument, =->>= that  puts it _last_, which is what  we wanted for the
two  forms but  not for  the last  one, with  lquery, which  needs the
parsed  html as  first argument.   So we  use =-<>>=:  the arrow  will
populate  the  _last_  argument,  except when  it  encounters  a  =<>=
placeholder. =-<>>= has a little name, "Diamond Spear".

** Creating a new project

   Before we write more functions we  should create a new project. For
   this  I  use a  skeleton  generator  which  will create  the  right
   =defsystem=, =defpackage= and so for us.

 I use  =cl-project=, which  also generates a  tests skeleton  (in the
 contrary of =quick-project=):

 #+BEGIN_SRC lisp
 (ql:quickload "cl-project")
 (cl-project:make-project #P"~/path/to/cl-torrents/")
 #+END_SRC

 Note that it  may be easier for  you sometimes if you  create your new
 Common  Lisp  projects  into =~/.quicklisp/local-projects=  (known  by
 Quicklisp)  or =~/.local/share/common-lisp/=  (known by  ASDF). Doing
 so, you will be able to =ql:quickload= your project right away.

** Adding our dependencies

Our new =cl-torrents.asd= looks like this:

#+BEGIN_SRC lisp
#|
  This file is a part of cl-torrents project.
|#

(in-package :cl-user)
(defpackage cl-torrents-asd
  (:use :cl :asdf))
(in-package :cl-torrents-asd)

(defsystem cl-torrents
  :version "0.1"
  :author ""
  :license ""
  :depends-on ()  ;; <== list of dependencies
  :components ((:module "src"
                :components
                ((:file "cl-torrents"))))
  :description ""
  :long-description
  …)
#+END_SRC

For pythonistas, it is very similar to a =setup.py=.

It  has the  =depends-on= paramater  which accepts  a list  of package
names. We have to register here =dexador= and the others:

#+BEGIN_SRC lisp
  :depends-on (:str
               :dexador
               :plump
               :lquery)
#+END_SRC

and =cl-arrows= if you wish.

** Loading the project

Open the  =.asdf= file and  compile and load  it. In Slime,  it's with
=C-c C-k= (=slime-compile-and-load-file=, see also the Emacs menu).

Now we can load the project at the REPL and install its dependencies:

#+BEGIN_SRC lisp
(asdf:make "cl-torrents" ;; or ql:quickload
; compiling file "/home/vince/projets/cl-torrents/src/cl-torrents.lisp" (written 28 AUG 2017 10:21:07 PM):
; compiling (IN-PACKAGE :CL-USER)
; compiling (DEFPACKAGE CL-TORRENTS ...)
; compiling (IN-PACKAGE :CL-TORRENTS)
; compiling (DEFPARAMETER *SEARCH-URL* ...)
; compiling (DEFPARAMETER *SELECTORS* ...)
; compiling (DEFUN TORRENTS ...)

; /home/vince/.cache/common-lisp/sbcl-1.3.19-linux-x64/home/vince/projets/cl-torrents/src/cl-torrents-tmp5GEXGEG5.fasl written
; compilation finished in 0:00:00.029
; compilation unit finished
T
#+END_SRC

And now we can use our function at the REPL.

We go into our package so that we can call our functions directly:

#+BEGIN_SRC lisp
(in-package :cl-torrents)
#+END_SRC

We could import the functions from our package and call them directly,
but we need to =export= them and we'll see that shortly.

We could  call them  with the  project prefix, but  we need  a doublon
colon because  our functions  are not exported  yet (so  they're kinda
private,  but not  strictly,  like  with a  method  starting with  the
underscore =_= in Python).

#+BEGIN_SRC lisp
(cl-torrents::torrents "matrix")
#+END_SRC

** Searching with our keywords

Until now  we only tried  things out with a  given search url,  set in
stone. It's time to insert our own search terms into this search url.

We'll put a ={KEYWORDS}= placeholder into the url:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr={KEYWORDS}&ID=&Limit=800&Letter=&Sorting=DSeeder"
    "base search url. {KEYWORDS} to be replaced by + separated words.")
#+END_SRC

which we will replace with a =+=-separated list of keywords.

With a little  look at the [[https://lispcookbook.github.io/cl-cookbook/strings.html]["strings" cookbook page]],  we'll go with the
little [[https://github.com/vindarel/cl-str][str]] library (our lib actually):

#+BEGIN_SRC lisp
(ql:quickload "str") ;; not needed if you loaded the asdf with the right dependencies.
#+END_SRC

Let's try:

#+BEGIN_SRC lisp
(defparameter words "matrix trilogy")
;; => WORDS
(str:words words)
;; => ("matrix" "trilogy")
(str:join "+" *) ;; the * is a REPL shortcut to insert the previous result. + inserts the previous input.
;; => "matrix+trilogy"
#+END_SRC

and voilà. We put this at the beginning of our search function and we get:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr={KEYWORDS}&ID=&Limit=800&Letter=&Sorting=DSeeder" "base search url. KEYWORDS to be replaced.")

(defun torrents (words)
  "Search torrents."
  (let* ((terms (str:words words))
         (query (str:join "+" terms))
         (*search-url* (str:replace-all "{KEYWORDS}" query *search-url*))
         (req (dex:get *search-url*))
         (html (plump:parse req))
         (res (lquery:$ html *selectors* (text))))
    res))
#+END_SRC

Let's try:

#+BEGIN_SRC lisp
(torrents "matrix trilogy")
#("
Title
"
  "Matrix FRENCH DVDRIP 1999 COOLUpload Date: 05.06.15 Size: 700,30 MB"
  "The Matrix Reloaded (2003) FullHD, Dual Audio: English + SpaUpload Date: 12.04.15 Size: 8,51 GB"
  "The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 DuUpload Date: 12.02.15 Size: 12,86 GB"
  "The Matrix Trilogy (1999-2003) BluRay BDRip 1080p AC3Upload Date: 15.09.15 Size: 23,29 GB"
  "The Matrix Trilogy (1999-2003) BDRip 1080p Dual Audio [ HindUpload Date: 14.01.15 Size: 10,23 GB"
  "The Matrix Revolutions (2003) BRRip [Dual Audio] [Hindi+Eng]Upload Date: 24.02.15 Size: 496,36 MB"
  "Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438Upload Date: 20.02.15 Size: 796,86 MB"
  "The Matrix Reloaded (2003) BRRip [Dual Audio] [Hindi+Eng] 50Upload Date: 22.02.15 Size: 496,39 MB"
  [and more results]
#+END_SRC

Cool !

We can commit  this, have a break  and enjoy how things  are going. It
was very easy, except one or two gotchas :)

Of course, we need  to get more stuff out of  this, like the torrent's
magnet link.

** Getting more torrent information

With =plump:serialize=  we could check  what html is inside  our plump
node:

#+BEGIN_SRC lisp
  (plump:serialize (second res))
  <td class="Title">
  <span class="ColorA">
  <a href="https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/" onclick="Javascript:OpenDetailPage('https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/'); return false;">Matrix FRENCH DVDRIP 1999 COOL
  </a>
  </span>
  <br/>
  <span class="ColorB VaA">Upload Date: 05.06.15
  </span>
  <span class="ColorB VaA">Size: 700,30 MB
  </span>
  <span class="ColorB"/>
  </td>
#+END_SRC

and we want to get the href with the torrent's url.

We know how to access the =a=:

#+BEGIN_SRC lisp
(defparameter *elt* (second res))
(lquery:$ *elt* "a" (text))
;; => #("Matrix FRENCH DVDRIP 1999 COOL")
#+END_SRC

it returns a plump node.

Let's try getting the href:

#+BEGIN_SRC lisp
(lquery:$ *elt* "a[href]" (text))
;; => #("Matrix FRENCH DVDRIP 1999 COOL")
#+END_SRC

this still returns the plump node.

With  the REPL  autocompletion and  then a  check at  the doc  we find
=lquery-funcs:attr= to extract attributes:

#+BEGIN_SRC lisp
(lquery-funcs:attr (lquery:$ *elt* "a") "href")
;; => #("https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/")
#+END_SRC

Ok.

But watch out,  the =#(…)= denotes a vector. We  get its first element
with

#+BEGIN_SRC lisp
(aref * 0)
#+END_SRC

(see the [[https://lispcookbook.github.io/cl-cookbook/data-structures.html][Cookbook's Data Structures page]]).

We put this in a function:

#+BEGIN_SRC lisp
(defun detail-page-url (node)
  "Extract the link of the details page. `node': plump node, containing the url."
  (let* ((href-vector (lquery-funcs:attr (lquery:$ node "a") "href"))
         (href (aref href-vector 0)))
    href))
#+END_SRC

which we can test (either write it  at the REPL either write it in the
project and compile, =C-c C-c= in Slime):

#+BEGIN_SRC lisp
(mapcar #'detail-page-url res)  ;; #' shorthand for function
;; =>
("https://piratebay.to/search/0/800/0/matrix/0/ATitle/1/"
 "https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/"
 "https://piratebay.to/torrent/2156107/The Matrix Reloaded (2003) FullHD, Dual Audio: English + Spa/"
 "https://piratebay.to/torrent/1885366/The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 Du/"
[…]
#+END_SRC

*** To the magnet link

We have the torrent's details page, we  know how to request it, now we
want to get the magnet link.

#+BEGIN_SRC lisp
(mapcar (lambda (it)
          (lquery-funcs:attr it "href"))
        (coerce (lquery:$ * "a") 'list))
;; =>
(NIL NIL NIL NIL NIL NIL NIL "https://piratebay.to/" "https://piratebay.to/"
 […]
 "http://imdb.com/title/tt1778413/" "https://piratebay.to/profile/Anonym"
 "https://piratebay.to/Downloader.php?ID=2289391&Filename=Matrix+FRENCH+DVDRIP+1999+COOL"
 "magnet:?xt=urn:btih:40eca43690cf1b99b0a4d485ebf4855d20b0bac5" "http://"
 […]
 "https://twitter.com/piratebayto" "https://www.facebook.com/thepiratebayto"
 "http://bitcoin.org" "bitcoin:1FX2wz8NiWPdtCGSrzn7j3NAg4VKqGovto" "/")
#+END_SRC

We  saw  what  I  consider  CL oddities  and  quirks  here,  for  sure
frustrating stuff  for the  (impatient) beginner.  =mapcar=  expects a
list and  lquery returns a vector,  so we had to  transform the result
with =coerce=.  Also  the name =mapcar= is a bit  outated, even if the
other map functions in the family  can be useful.  There is =map= that
takes its output type has first  parameter: =(map 'list …)=. There are
fixes.

We could  use [[https://lispcookbook.github.io/cl-cookbook/cl21.html][cl21]]'s =map=, which works on  vectors too.

Still with cl21, we can write shorter lambdas, with the shorthand =lm=
or with:

#+BEGIN_SRC lisp
(map ^(lquery-funcs:attr % "href") …) ;; with more arguments, use %1, %2,…
#+END_SRC

Cl21 defines and  rewrites a lot of stuff to  offer shorter and sanier
ways of doing (this,  hash-tables, regexps,…), towards more functional
programming, and more generics (functions that work on many types, not
one function  per type). It still  is a CL  library, so we can  use it
alongside the usual CL in our project.

It is written  by a super productive and innovative  CL hacker and has
600+ stars  on github.  Nevertheless, it wasn't  touched in  two years
and, as it lacks docstrings and  direction, we can be surprised by the
new implementation of some functions. No  need to say the community is
divided on this subject.

Filtering:

#+BEGIN_SRC lisp
(remove-if-not (lambda (it)
                 (str:starts-with? "magnet" it))
               *)
#+END_SRC

Here, I  used again a short  verb from an external  library for string
manipulation. The CL way would be something like:

#+BEGIN_SRC lisp
(string= "magnet-foo" "magnet" :start1 0 :end1 (length "magnet"))
T
#+END_SRC

and yet we must handle nils, differences of length,… so boring.


** First test - end to end test

We wouldn't be called a developper if we didn't write any test.

Our favorite test framework (which we found on the [[https://github.com/CodyReichert/awesome-cl][Awesome CL list]]) is
[[https://github.com/fukamachi/prove][Prove]].

*** Unit testing solutions

Since we do webscraping, the result  from the network calls are likely
to be  different each time.  That's not cool  for unit tests.  We must
find a way to fake the result  of =dex:get= and return the same thing,
always.

That's the  goal of [[https://github.com/tsikov/vcr/][vcr]]:

#+BEGIN_QUOTE
Store and replay results of http calls for easier testing of external services.
#+END_QUOTE

You  recall what's  a Videocassette  Recorder,  right ?   You give  it
something to record and it can play it back.  It's a common concept in
testing,  there are  popular libraries  on other  ecosystems (  in the
Python world for  instance).  Well, vcr isn't on  Quicklisp yet (which
is ok, we can clone  it on =~/.quicklisp/local-projects/= or use [[https://github.com/fukamachi/qlot][Qlot]])
and it's very new, so there might be bugs.

We might also save a piece of html in the testing directory and have a
call to =dex:get= return that. Coming from the "blob languages" world,
we  looked for  a mocking  library.  There are,  like [[https://github.com/Chream/mockingbird/][Mockingbird]]  and
[[https://github.com/Ferada/cl-mock][Cl-mock]]:

#+BEGIN_QUOTE
This package provides some useful stubbing and mocking macros for unit
testing.  Used  when specified  functions  in  a  test should  not  be
computed but should instead return a provided constant value.
#+END_QUOTE

They also  provide ways to check  if a given function  was called, how
many  times, etc.   However, *for  simple  mocking we  can simply  use
closures*. Great feature of the language.

All that  being said, we'll write  the simplest test at  the moment :)
We'll simply  call our search function  and check it didn't  error out
and had some results in.

The file =t/cl-torrents.lisp= looks like this:

#+BEGIN_SRC lisp
(in-package :cl-user)
(defpackage cl-torrents-test
  (:use :cl
        :cl-torrents  ;; => import our exported functions in cl-torrents.lisp
        :prove))      ;; => import all Prove verbs (like python's "from prove import *")
(in-package :cl-torrents-test)

;; NOTE: To run this test file, execute `(asdf:test-system :cl-torrents)' in your Lisp.

(plan nil)  ;; optional Prove setting.

;; blah blah blah.

(finalize)
#+END_SRC

We add:

#+BEGIN_SRC lisp
(ok (torrents "matrix"))
#+END_SRC

we compile it (=C-c C-c=) and it runs the test in the REPL.


*** Exporting functions

We need  to export symbols  in order to use  them from the  outside of
their source  file, in order  to use them directly  (=use-package=) or
with =(my-package:my-function)=. If we don't export them, we can still
access them with a double colon: =(my-package::my-function)=.

Our package definition contains this:

#+BEGIN_SRC lisp
(defpackage cl-torrents
  (:use :cl))
#+END_SRC

We add it an =export= clause:

#+BEGIN_SRC lisp
(defpackage cl-torrents
  (:use :cl)
  (:export :torrents))
#+END_SRC

We could also mark the functions to export with a decorator à-la Python,
like this:

#+BEGIN_SRC lisp
@export
(defun torrents (…)
    …)
#+END_SRC

which  is quite  elegant and  can be  handy. This  is doable  with the
[[https://github.com/m2ym/cl-annot][cl-annot]] library, and it also requires a little Slime configuration.

** Conclusion

This leads us to the end of part one.

We now want or need more:

- getting more content (seeders)
- downloading the torrent file ?
- error handling (network errors or timeout, unexpected errors)
- scraping other sites, asynchronously  (the asynchronous part will be
  straightforward, there's  a library for  that and it's  one function
  change)
- some tests
- some cache
- a command line tool
- some more functionnality (getting many magnet links at once)
- …
