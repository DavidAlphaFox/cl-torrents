#+OPTIONS: html-link-use-abs-url:nil html-postamble:auto
#+OPTIONS: html-preamble:t html-scripts:t html-style:t
#+OPTIONS: html5-fancy:nil tex:t
#+HTML_DOCTYPE: xhtml-strict
#+HTML_CONTAINER: div
#+DESCRIPTION: Scraping the Pirate Bay in Common Lisp
#+KEYWORDS: common lisp web-scraping pirate-bay
#+HTML_LINK_HOME:
#+HTML_LINK_UP:
#+HTML_MATHJAX:
#+HTML_HEAD:
#+HTML_HEAD_EXTRA:
#+SUBTITLE:
#+INFOJS_OPT:
#+CREATOR: <a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.4.1 (<a href="http://orgmode.org">Org</a> mode 9.0.3)
#+LATEX_HEADER:

#+AUTHOR: vindarel

#+SETUPFILE: theme-readtheorg.setup


* Part 1

Scraping   The   Pirate   Bay   is    easy,   they   don't   rely   on
javascript-generated pages. We just have to:

- get the html page ([[http://quickdocs.org/dexador/][dexador]]: =(dex:get <url>)=)
- parse the html into a data structure ([[https://shinmera.github.io/plump/][plump]]: =(plump:parse <html>)=)
- search   with  CSS   selectors  ([[https://shinmera.github.io/lquery][lquery]]:   =(lquery:"  <parsed-html>
  <selectors>)=)

Let's go.

Install our dependencies right away:

#+BEGIN_SRC lisp
(ql:quickload '("dexador" "plump" "lquery"))
#+END_SRC

To begin  with, we do  a search on the  website and we  copy-paste the
url. We get one like this:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr=matrix&ID=&Limit=800&Letter=&Sorting=DSeeder"
    "the url to search matrix.")
#+END_SRC

It has our search term in it (=matrix=) along with url parameters.

It also sorts the results by number of seeders for us :) (=&Sorting=DSeeder=).

We will use CSS selectors to extract information from the web page, so
we can use  our browser's developer tools to inspect  the structure of
the page  and guess our  selectors: right  click on a  result's title,
choose "inspect element". It highlights some html similar to this:

#+BEGIN_SRC html
  <td class="Title">
    <span class="ColorA">
      <a href="https://piratebay.to/torrent/1922147/Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438/" onclick="Javascript:OpenDetailPage('https://piratebay.to/torrent/1922147/Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438/'); return false;">Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438 </a>
    </span>
    <br>
      <span class="ColorB VaA">Upload Date: 20.02.15 </span>
      <span class="ColorB VaA">Size: 796,86 MB </span>
      <span class="ColorB"> </span>
  </td>
#+END_SRC


The title is  well delimited so we'll start selecting  our elements by
the CSS class =Title=, which gives:

#+BEGIN_SRC lisp
(defparameter *selectors* ".Title")
#+END_SRC

If  you are  not accostumed  to CSS  selectors, I  like this  webpage:
https://codingsec.net/2016/12/select-specific-text-css-using-selectors/.

** Trying out at the REPL

Let's try in the REPL:

#+BEGIN_SRC lisp
(defparameter html (dex:get *search-url*)) ;; returns the html
(defparameter parsed (plump:parse html))   ;; returns a list of plump elements
(defparameter results (lquery:$ parsed *selectors*)) ;; returns a list of stuff
(setf results (lquery:$ parsed *selectors* (text)))  ;; returns text, i.e. the titles
#+END_SRC

A little explanation for the =lquery=  line: the last =(text)= part is
an lquery thing to get the text representation of the node, instead of
a lquery internal object.

I  like to  check the  html content  of the  plump nodes.  We use  the
=serialize= plump function (the second function from the doc ;) ):

#+BEGIN_SRC lisp
CL-TORRENTS> (plump:serialize (first results))
#+END_SRC

but we get an error:

#+BEGIN_QUOTE
The value #(
... all the content of results here ...
)
is not of type LIST
…
#+END_QUOTE

Sorry for  the inconvenience. Indeed, lquery  returns a vector,
not a list (we  can see that with =#()= that denotes  a vector), so we
can not use =first= but have to use =(aref <vector> 0)= instead, or we
have to =coerce= the result to a list.

(see the [[https://lispcookbook.github.io/cl-cookbook/data-structures.html][Cookbook's Data Structures page]]).

Personnally I find this frustrating, particularly being used in Python
to access  lots of data  structures in the  same manner.  If  you feel
like  fixing this,  have a  look at  [[https://lispcookbook.github.io/cl-cookbook/cl21.html][CL21]], "Common  Lisp for  the 21st
century" which,  amongst other  features, redefines some  functions to
make them generic (that work on lists, vectors, hashmaps,…). CL21 is a
CL library, meaning we can of  course use the others CL libraries with
it, or that  we can use cl21  alongside CL in only in  some places but
not in all our project (like in only one file, one "package").

It is written  by a super productive and innovative  CL hacker and has
600+ stars  on github.  Nevertheless, it wasn't  touched in  two years
and, as it lacks docstrings and  direction, we can be surprised by the
new implementation of some functions. No  need to say the community is
divided on this subject.

Allright so, back to printing the html content of our first result:

#+BEGIN_SRC text
CL-TORRENTS> (plump:serialize (aref results 0))
<th class="Title header ">
<a href="https://piratebay.to/search/0/800/0/matrix/0/ATitle/1/">Title</a>
</th>
">"
#+END_SRC

gosh, there  is not much in  it.  I was  too quick in defining  my CSS
selector.  This  first result should  not be catched by  our selector,
because it is not a link to a torrent but only the header of the table
(see "Title header" and the =th= ?).

But that's not  all. I also want  to scrape the number  of seeders and
leechers and  the =.Title= selector  doesn't include them  (this I see
with the browser's web inspector). If I select the including =tr= I'll
get all the data,  and I must ensure to select  those =tr= from inside
the body  of the table,  =tbody=.  So I'll  use a first  selector that
will return a list of elements of the table:

#+BEGIN_SRC lisp
(setf *selectors* "tbody tr")
#+END_SRC

and then for each result I'll get the title and the number of seeders.

So I can scrape again my search results with the new selector:

#+BEGIN_SRC lisp
(setf results (lquery:$ parsed *selectors* (text)))
#+END_SRC

this should print interesting stuff, like our torrents titles and even
strings like =S: 16L: 1= which are indeed our seeders and leechers.

I check the html content:

#+BEGIN_SRC lisp
  CL-TORRENTS> (plump:serialize (aref res 0))
  ;todo: insert here html content with seeders too.
#+END_SRC

allright, good. It has the link  to the torrent's page inside the href
of the "a" element, as well as the seeders count.

Note that we  can also inspect the results with  the mouse: left/right
clicks  on the  elements printed  in the  REPL get  us into  the Slime
inspector.

** Putting it together in a function

We came up with this function:

#+BEGIN_SRC lisp
(defun torrents (words)
  ""
  (let* ((html (dex:get *search-url*))
         (parsed (plump:parse html))
         (res (lquery:$ parsed *selectors* (text))))
    res))
#+END_SRC

and if  you prefer a  threading macro /  pipes, no problem,  but we'll
load another external library:

#+BEGIN_EXPORT latex
(ql:quickload "cl-arrows")
;; and we import its symbols:
(use-package "cl-arrows")
#+END_EXPORT

#+BEGIN_SRC lisp
(-<>> *search-url*
  (dex:get)
  (plump:parse)
  (lquery:$ <> *selectors* (text)))
#+END_SRC

[[https://github.com/nightfly19/cl-arrows][cl-arrows]] defines  a few  threading macros. The  classic one  would be
=->=,  which inserts  the  result  of the  preceding  form as  _first_
argument, =->>= that  puts it _last_, which is what  we wanted for the
two  forms but  not for  the last  one, with  lquery, which  needs the
parsed  html as  first argument.   So we  use =-<>>=:  the arrow  will
populate  the  _last_  argument,  except when  it  encounters  a  =<>=
placeholder. =-<>>= has a little name, "Diamond Spear".

** Creating a new project

   Before we write more functions we  should create a new project. For
   this  I  use a  skeleton  generator  which  will create  the  right
   =defsystem=, =defpackage= and so for us.

 I use  =cl-project=, which  also generates a  tests skeleton  (in the
 contrary of =quick-project=):

 #+BEGIN_SRC lisp
 (ql:quickload "cl-project")
 (cl-project:make-project #P"~/path/to/cl-torrents/")
 #+END_SRC

 Note that it  may be easier for  you sometimes if you  create your new
 Common  Lisp  projects  into =~/.quicklisp/local-projects=  (known  by
 Quicklisp)  or =~/.local/share/common-lisp/=  (known by  ASDF). Doing
 so, you will be able to =ql:quickload= your project right away.

** Adding our dependencies

Our new =cl-torrents.asd= looks like this:

#+BEGIN_SRC lisp
#|
  This file is a part of cl-torrents project.
|#

(in-package :cl-user)
(defpackage cl-torrents-asd
  (:use :cl :asdf))
(in-package :cl-torrents-asd)

(defsystem cl-torrents
  :version "0.1"
  :author ""
  :license ""
  :depends-on ()  ;; <== list of dependencies
  :components ((:module "src"
                :components
                ((:file "cl-torrents"))))
  :description ""
  :long-description
  …)
#+END_SRC

For pythonistas, it is very similar to a =setup.py=.

It  has the  =depends-on= paramater  which accepts  a list  of package
names. We have to register here =dexador= and the others:

#+BEGIN_SRC lisp
  :depends-on (:str
               :dexador
               :plump
               :lquery)
#+END_SRC

and =cl-arrows= if you wish.

** Loading the project

Open the  =.asdf= file and  compile and load  it. In Slime,  it's with
=C-c C-k= (=slime-compile-and-load-file=, see also the Emacs menu).

Now we can load the project at the REPL and install its dependencies:

#+BEGIN_SRC lisp
(asdf:make "cl-torrents" ;; or ql:quickload
; compiling file "/home/vince/projets/cl-torrents/src/cl-torrents.lisp" (written 28 AUG 2017 10:21:07 PM):
; compiling (IN-PACKAGE :CL-USER)
; compiling (DEFPACKAGE CL-TORRENTS ...)
; compiling (IN-PACKAGE :CL-TORRENTS)
; compiling (DEFPARAMETER *SEARCH-URL* ...)
; compiling (DEFPARAMETER *SELECTORS* ...)
; compiling (DEFUN TORRENTS ...)

; /home/vince/.cache/common-lisp/sbcl-1.3.19-linux-x64/home/vince/projets/cl-torrents/src/cl-torrents-tmp5GEXGEG5.fasl written
; compilation finished in 0:00:00.029
; compilation unit finished
T
#+END_SRC

And now we can use our function at the REPL.

We go into our package so that we can call our functions directly:

#+BEGIN_SRC lisp
(in-package :cl-torrents)
#+END_SRC

We could import the functions from our package and call them directly,
but we need to =export= them and we'll see that shortly.

We could  call them  with the  project prefix, but  we need  a doublon
colon because  our functions  are not exported  yet (so  they're kinda
private,  but not  strictly,  like  with a  method  starting with  the
underscore =_= in Python).

#+BEGIN_SRC lisp
(cl-torrents::torrents "matrix")
#+END_SRC

** Searching with our keywords

Until now  we only tried  things out with a  given search url,  set in
stone. It's time to insert our own search terms into this search url.

We'll put a ={KEYWORDS}= placeholder into the url:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr={KEYWORDS}&ID=&Limit=800&Letter=&Sorting=DSeeder"
    "base search url. {KEYWORDS} to be replaced by + separated words.")
#+END_SRC

which we will replace with a =+=-separated list of keywords.

With a little  look at the [[https://lispcookbook.github.io/cl-cookbook/strings.html]["strings" cookbook page]],  we'll go with the
little [[https://github.com/vindarel/cl-str][str]] library (our lib actually):

#+BEGIN_SRC lisp
(ql:quickload "str") ;; not needed if you loaded the asdf with the right dependencies.
#+END_SRC

Let's try:

#+BEGIN_SRC lisp
(defparameter words "matrix trilogy")
;; => WORDS
(str:words words)
;; => ("matrix" "trilogy")
(str:join "+" *) ;; the * is a REPL shortcut to insert the previous result. + inserts the previous input.
;; => "matrix+trilogy"
#+END_SRC

and voilà. We put this at the beginning of our search function and we get:

#+BEGIN_SRC lisp
(defparameter *search-url* "https://piratebay.to/search/?FilterStr={KEYWORDS}&ID=&Limit=800&Letter=&Sorting=DSeeder" "base search url. KEYWORDS to be replaced.")

(defun torrents (words)
  "Search torrents."
  (let* ((terms (str:words words))
         (query (str:join "+" terms))
         (*search-url* (str:replace-all "{KEYWORDS}" query *search-url*))
         (req (dex:get *search-url*))
         (html (plump:parse req))
         (res (lquery:$ html *selectors* (text)))
         (res-list (coerce res 'list))))

    res-list))
#+END_SRC

In the end we prefer to return a list, rather than a vector.

Let's try:

#+BEGIN_SRC lisp
(torrents "matrix trilogy")
#("Matrix FRENCH DVDRIP 1999 COOLUpload Date: 05.06.15 Size: 700,30 MB"
  "The Matrix Reloaded (2003) FullHD, Dual Audio: English + SpaUpload Date: 12.04.15 Size: 8,51 GB"
  "The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 DuUpload Date: 12.02.15 Size: 12,86 GB"
  "The Matrix Trilogy (1999-2003) BluRay BDRip 1080p AC3Upload Date: 15.09.15 Size: 23,29 GB"
  "The Matrix Trilogy (1999-2003) BDRip 1080p Dual Audio [ HindUpload Date: 14.01.15 Size: 10,23 GB"
  "The Matrix Revolutions (2003) BRRip [Dual Audio] [Hindi+Eng]Upload Date: 24.02.15 Size: 496,36 MB"
  "Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438Upload Date: 20.02.15 Size: 796,86 MB"
  "The Matrix Reloaded (2003) BRRip [Dual Audio] [Hindi+Eng] 50Upload Date: 22.02.15 Size: 496,39 MB"
  [and more results]
#+END_SRC

Cool !

We can commit  this, have a break  and enjoy how things  are going. It
was very easy, except one or two gotchas :)

Of course, we need  to get more stuff out of  this, like the torrent's
magnet link.

** Formatting output

   Our  =torrents= function  prints  out intelligable  output, but  we
   don't control  it yet. We want  to iterate over the  search results
   and print exactly what we want.

   So first  we need to  extract the title,  with the CSS  selector we
   found at the beginning.

#+BEGIN_SRC lisp
(defun result-title (node)
  "Return the title of a search result."
  (aref
   (lquery:$ node ".Title a" (text))
   0))
#+END_SRC

    When we iterate over the result list:

#+BEGIN_SRC lisp
(defun display-results (&optional (results *last-search*) (stream t))
  "Results: list of plump nodes. We want to print a numbered list with the needed information (torrent title, the number of seeders,..."
  (mapcar (lambda (it)
            ;; do not rely on *last-search*.
            (format stream "~a~%" (result-title it)))
          results)
  t)
#+END_SRC

    it prints something like:

#+BEGIN_SRC text
Matrix FRENCH DVDRIP 1999 COOL
The Matrix Reloaded (2003) FullHD, Dual Audio: English + Spa
The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 Du
The Matrix Trilogy (1999-2003) BluRay BDRip 1080p AC3
The Matrix Trilogy (1999-2003) BDRip 1080p Dual Audio [ Hind
Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438
...
#+END_SRC

    What we have in  mind is to print the index of  the result next to
    it, and for convenience to print the first result last, so that it
    stays to the bottom and it's easier to see from the prompt.

    We have  a quick look at  the [[https://lispcookbook.github.io/cl-cookbook/strings.html#string-formatting][Cookbook for string  formatting]] (the
    simplest directive is =~a=, for aesthetics, and justifying text on
    the left is with =~@a=). =~%= is the newline.

#+BEGIN_SRC lisp
(defun display-results (&optional (results *last-search*) (stream t))
  "Results: list of plump nodes. We want to print a numbered list with the needed information (torrent title, the number of seeders,..."
  (mapcar (lambda (it)
            (format stream "~3@a: ~65a ~%"
                    (position it *last-search*) ;; <-- find the position of the result in the list
                    (result-title it)))  ;; <-- we reverse the list
          (reverse results))

          t)
#+END_SRC

Here we use another global  variable that we introduced eventually. In
the end of  our =torrents= function, we add this:

#+BEGIN_SRC lisp
    (setf *last-search* res-list)
#+END_SRC

so that our search results are saved in this variable which we define:

#+BEGIN_SRC
(defvar *last-search* nil
    "Remembering the last search (should be an hash-map).")
#+END_SRC

and we can easily access this result list elsewhere.


So, we get this formatting:

#+BEGIN_SRC text
198: Arturia - Matrix-12 V v1.1.0.522 OS X [PitcHsHiFTeR][dada]
197: Arturia - Matrix-12 V v1 1 0 522 R2 AU AAX VST VST3 ST OS X
196: Native Instruments - Maschine Expansion Golden Kingdom HYBRI
195: Arturia - Matrix 12-V v1.0.1.9 OS X [HEXWARS][dada]
194: PPPD-374 Ikuchichi Beauty Salon That Just Busty Beauty Is In
193: THE MATRIX TRILOGY: Complete Collection - DVDRip
...
 10: Matrix Reloaded (2003)Blu-Ray 720p Dublado PT-BR - mo93438
  9: Matrix Revolutions (2003)Blu-Ray 720p Dublado PT-BR - mo9343
  8: Die Matrix Trilogie - 1 bis 3 - KOMPLETT
  7: The Matrix Reloaded (2003) BRRip [Dual Audio] [Hindi+Eng] 50
  6: The Matrix Revolutions (2003) BRRip [Dual Audio] [Hindi+Eng]
  5: Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438
  4: The Matrix Trilogy (1999-2003) BDRip 1080p Dual Audio [ Hind
  3: The Matrix Trilogy (1999-2003) BluRay BDRip 1080p AC3
  2: The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 Du
  1: The Matrix Reloaded (2003) FullHD, Dual Audio: English + Spa
  0: Matrix FRENCH DVDRIP 1999 COOL
T
#+END_SRC

    The indexes are  aligned on 3 digits on the  right with =~3@a= and
    titles are truncated at 65 characters,  nice :) It will be easy to
    add more information on the right side (seeders, leechers).


** Getting more torrent information

With =plump:serialize=  we could check  what html is inside  our plump
node:

#+BEGIN_SRC lisp
  (plump:serialize (second res))
  <td class="Title">
  <span class="ColorA">
  <a href="https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/" onclick="Javascript:OpenDetailPage('https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/'); return false;">Matrix FRENCH DVDRIP 1999 COOL
  </a>
  </span>
  <br/>
  <span class="ColorB VaA">Upload Date: 05.06.15
  </span>
  <span class="ColorB VaA">Size: 700,30 MB
  </span>
  <span class="ColorB"/>
  </td>
#+END_SRC

We want to get  the torrent's page, the url in  the firts =href=. From
this page we'll be able to access to the magnet link.

We know how to access the =a=:

#+BEGIN_SRC lisp
(defparameter *elt* (first res))
(lquery:$ *elt* "a" (text))
;; => #("Matrix FRENCH DVDRIP 1999 COOL")
#+END_SRC

it returns a plump node.

With  the REPL  autocompletion and  then a  check at  the doc  we find
=lquery-funcs:attr= to extract attributes:

#+BEGIN_SRC lisp
(lquery-funcs:attr (lquery:$ *elt* "a") "href")
;; => #("https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/")
#+END_SRC

Ok. But watch out again, the result is a vector (of one element).

We put this in a function:

#+BEGIN_SRC lisp
(defun detail-page-url (node)
  "Extract the link of the details page. `node': plump node, containing the url."
  (let* ((href-vector (lquery-funcs:attr (lquery:$ node "a") "href"))
         (href (aref href-vector 0)))
    href))
#+END_SRC

which we can test (either write it  at the REPL either write it in the
project and compile, =C-c C-c= in Slime):

#+BEGIN_SRC lisp
(mapcar #'detail-page-url res)  ;; #' shorthand for function
;; =>
("https://piratebay.to/search/0/800/0/matrix/0/ATitle/1/"
 "https://piratebay.to/torrent/2297350/Matrix FRENCH DVDRIP 1999 COOL/"
 "https://piratebay.to/torrent/2156107/The Matrix Reloaded (2003) FullHD, Dual Audio: English + Spa/"
 "https://piratebay.to/torrent/1885366/The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 Du/"
[…]
#+END_SRC

*** To the magnet link

We have the torrent's details page, we  know how to request it, now we
want to get the magnet link.

We experiment, and get a /list/ of the links inside this page:

#+BEGIN_SRC lisp
(mapcar (lambda (it)
          (lquery-funcs:attr it "href"))
        (coerce (lquery:$ * "a") 'list))
;; =>
(NIL NIL NIL NIL NIL NIL NIL "https://piratebay.to/" "https://piratebay.to/"
 […]
 "http://imdb.com/title/tt1778413/" "https://piratebay.to/profile/Anonym"
 "https://piratebay.to/Downloader.php?ID=2289391&Filename=Matrix+FRENCH+DVDRIP+1999+COOL"
 "magnet:?xt=urn:btih:40eca43690cf1b99b0a4d485ebf4855d20b0bac5" "http://"
 […]
 "https://twitter.com/piratebayto" "https://www.facebook.com/thepiratebayto"
 "http://bitcoin.org" "bitcoin:1FX2wz8NiWPdtCGSrzn7j3NAg4VKqGovto" "/")
#+END_SRC

in the result, there's our magnet link.

We  saw what  I consider  CL  oddities and  quirks here,  than can  be
frustrating for the (impatient) beginner.  =mapcar= expects a list and
lquery  returns a  vector,  so we  had to  transform  the result  with
=coerce=.  Also  the name =mapcar= is  unusual, even if the  other map
functions in  the family can be  useful.  There is a  =map= that takes
its output type has first parameter: =(map 'list …)=.

We could use  [[https://lispcookbook.github.io/cl-cookbook/cl21.html][cl21]]'s =map=, which works  on vectors too so  no need of
the =coerce=.

Still with cl21, we can write shorter lambdas, with the shorthand =lm=
or with the =^= reader  macro and accessing arguments with =%1=... =%n=
or simply =%= for the first one:

#+BEGIN_SRC lisp
;; todo: (lquery:$ … (attr :href)) cf cookbook
(map ^(lquery-funcs:attr % "href") …)
#+END_SRC

We filter the list above to extract the magnet link:

#+BEGIN_SRC lisp
(remove-if-not (lambda (it)
                 (str:starts-with? "magnet" it))
               *)
#+END_SRC

Here, I  used again a short  verb from an external  library for string
manipulation. The CL way would be something like:

#+BEGIN_SRC lisp
(string= "magnet-foo" "magnet" :start1 0 :end1 (length "magnet"))
T
#+END_SRC

and yet we must handle nils, differences of length,… so boring.

We end up with  the following functions:


#+BEGIN_SRC lisp
(defun magnet-link-from (node)
  "Extract the magnet link from a `torrent' result."
  (let* ((url (detail-page-url node))
         (html (request-details url))
         (parsed (plump:parse html)))
    (find-magnet-link parsed)))
#+END_SRC


- extract the magnet link from an  html (the page of a torrent's page)
  parsed with plump.

#+BEGIN_SRC lisp
(defun find-magnet-link (parsed)
  "Extract the magnet link. `parsed': plump:parse result."
  (let* ((hrefs (mapcar (lambda (it)
                          (lquery-funcs:attr it "href"))
                        (coerce (lquery:$ parsed "a") 'list)))
         (magnet (remove-if-not (lambda (it)
                                  (str:starts-with? "magnet" it))
                                hrefs)))
    (first magnet)))
#+END_SRC

- this one gets  a plump node (from the search  results), extracts the
  url of  the torrent's page and  calls our function above  to extract
  the magnet link:

#+BEGIN_SRC lisp
(defun magnet-link-from (node)
  "Extract the magnet link from a `torrent' result."
  (let* ((url (detail-page-url node))
         (html (dex:get url))
         (parsed (plump:parse html)))
    (find-magnet-link parsed)))
#+END_SRC

- finally we need an easy way to call the function above and give it a
  reference to a search result.

#+BEGIN_SRC lisp
(defun magnet (index)
  "Search the magnet from last search's `index''s result."
  (magnet-link-from (elt *last-search* index)))
#+END_SRC

And we simply use it like so: given an output like

#+BEGIN_SRC text
...
  5: Matrix (1999)Blu-Ray 720p Dublado PT-BR - mo93438
  4: The Matrix Trilogy (1999-2003) BDRip 1080p Dual Audio [ Hind
  3: The Matrix Trilogy (1999-2003) BluRay BDRip 1080p AC3
  2: The Matrix Trilogy (1999-2003) + Extras 1080p BluRay x264 Du
  1: The Matrix Reloaded (2003) FullHD, Dual Audio: English + Spa
  0: Matrix FRENCH DVDRIP 1999 COOL
T
#+END_SRC

    We request the magnet link with:

#+BEGIN_SRC lisp
CL-TORRENTS> (magnet 0)
"magnet:?xt=urn:btih:40eca43690cf1b99b0a4d485ebf4855d20b0bac5"
#+END_SRC


** Exporting functions

We need  to export symbols  in order to use  them from the  outside of
their source  file, in order  to use them directly  (=use-package=) or
with =(my-package:my-function)=. If we don't export them, we can still
access them with a double colon: =(my-package::my-function)=.

Our package definition contains this:

#+BEGIN_SRC lisp
(defpackage cl-torrents
  (:use :cl))
#+END_SRC

We add it an =export= clause:

#+BEGIN_SRC lisp
(defpackage cl-torrents
  (:use :cl)
  (:export :torrents
           :magnet))
#+END_SRC

We could also mark the functions to export with a decorator à-la Python,
like this:

#+BEGIN_SRC lisp
@export
(defun torrents (…)
    …)
#+END_SRC

which  is quite  elegant and  can be  handy. This  is doable  with the
[[https://github.com/m2ym/cl-annot][cl-annot]] library. It also requires a small Slime configuration.


** Tests

We wouldn't be called a developper if we didn't write any test.

Our favorite test framework (which we found on the [[https://github.com/CodyReichert/awesome-cl][Awesome CL list]]) is
[[https://github.com/fukamachi/prove][Prove]].

The file =t/cl-torrents.lisp=, generated by cl-project, looks like this:

#+BEGIN_SRC lisp
(in-package :cl-user)
(defpackage cl-torrents-test
  (:use :cl
        :cl-torrents  ;; => import our exported functions in cl-torrents.lisp
        :prove))      ;; => import all Prove verbs (like python's "from prove import *")
(in-package :cl-torrents-test)

;; NOTE: To run this test file, execute `(asdf:test-system :cl-torrents)' in your Lisp.

(plan nil)  ;; optional Prove setting.

;; blah blah blah.

(finalize)
#+END_SRC

We add our first and simplest test:

#+BEGIN_SRC lisp
(ok (torrents "matrix"))
#+END_SRC

It only checks that this command doesn't fail. We compile it with =C-c
C-c= and we see it run in the REPL.

This  test does  a network  call: it  is not  an unit  test.  It's  an
"end-to-end" test  instead, and  that's ok  we need  one too  :) We'll
write unit  tests now, and  also hide the  large output of  the search
results.


*** Unit tests

Since we do webscraping, the result  from the network calls are likely
to  be  different  each  time.    That's  good  for  "integration"  or
"end-to-end" tests but not for unit tests.  We must find a way to fake
the result of =dex:get= and return the same thing, always.

A solution  is to save  a piece of html  in the testing  directory and
make sure  that a call to  =dex:get= returns it. In  other words we're
looking to  mock functions calls.   There's a  library to do  this and
more, [[https://github.com/Chream/mockingbird/][Mockingbird]]:

#+BEGIN_QUOTE
This package provides some useful stubbing and mocking macros for unit
testing.  Used  when specified  functions  in  a  test should  not  be
computed but should instead return a provided constant value.
#+END_QUOTE

It also makes possible to check if  a given function was called, if so
how  many times,  with what  arguments, etc,  which is  very nice  for
tests.

Ok, let's go. We record the html of the search results:

: mkdir t/assets/
: wget  -O t/assets/search-matrix.html https://piratebay.to/search/\?FilterStr\=matrix\&ID\=1\&ID\=\&Limit\=800\&Letter\=\&Sorting\=DSeeder

We need to read this file into a string. A quick look to the Cookbook:
(unfortunately this is not a one-liner :( )

#+BEGIN_SRC lisp
(defun file-to-string (path)
  "Return the given file as a string."
    (with-open-file (stream path
                            :external-format :utf-8)
      (let ((data (make-string (file-length stream))))
        (read-sequence data stream)
        data)))
#+END_SRC

and we use it:

#+BEGIN_SRC lisp
;; Load the search result html from a file.
(defparameter htmlpage (file-to-string #p"t/assets/search-matrix.html"))
#+END_SRC

From mockingbird, we  need =with-dynamic-stubs=. We'll mock  a call to
=dex:get=:

#+BEGIN_SRC lisp
(with-dynamic-stubs ((dex:get htmlpage))
  (ok (torrents "matrix") "torrent search ok"))
#+END_SRC

This test  (run with  =C-c C-c=)  should not make  a network  call and
should  always  return  the  matrix  results.   Indeed,  if  we  write
=(torrents "dysney")= instead it returns (and prints) the same.

So from here, we  can write more unit tests. When we  want to test the
=magnet= function, we  realize that we need to  mock another =dex:get=
call, the one  that requests the html page of  a particular result. We
extract the network  call from the function, what we  should have done
from  the beginning  as best  practice  actually (we'll  also need  to
expand this with error checking and more):

#+BEGIN_SRC lisp
(defun request-details (url)
  "Get the html page of the given url. Mocked in unit tests."
  (dex:get url))
#+END_SRC

Now we mock it. Extending the test above:

#+BEGIN_SRC lisp
(with-dynamic-stubs ((dex:get htmlpage)
                     (cl-torrents::request-details resultpage))

  (ok (torrents "matrix" out) "torrent search ok")

  (ok (str:starts-with? "magnet" (magnet 0))
      "magnet <i> returns the the magnet link from search result."))
#+END_SRC

Our tests  still write a  lot of stuff  on standard output,  let's fix
that.

*** Capturing output

We knew giving an optional stream parameter to our =torrents= function
would be useful sometime:

#+BEGIN_SRC lisp
(defun torrents (words &optional (stream t)) ...)
#+END_SRC

The =t=  means "print  to standard  output". The trick  is to  give it
another stream, notably one that goes to a string:

#+BEGIN_SRC lisp
  (ok (with-output-to-string (out)
        (torrents "matrix" out)) "torrent search ok")
#+END_SRC

and that's it, our tests are silent now.

We can write more of them.

*** Isolating tests (with a macro)

I'm not bothered (yet?)  by the way we wrote tests  above, all of them
inside  a =with-dynamic-stubs=  macro.  It's just  that  they are  not
isolated,  at each  =C-c  C-c= it  compiled and  ran  the whole  form,
running all our tests.

If we  want, we  can isolate  them, each  one under  its own  and same
=with-dynamic-stubs=. But as soon as  there's repetition… it's time to
refactor with  a macro. There's  not much to it  but we're glad  for a
little practice.

Each test will be of the form:

#+BEGIN_SRC lisp
(with-dynamic-stubs (<stubs>)
    <tests>)
#+END_SRC

The only argument to our macro is a form containing the tests:

#+BEGIN_SRC lisp
(defmacro with-mocked-search-results (body)
#+END_SRC

We get this simple macro:

#+BEGIN_SRC lisp
(defmacro with-mocked-search-results (body)
    `(with-dynamic-stubs ((dex:get htmlpage)
                          (cl-torrents::request-details resultpage))
         ,body))
#+END_SRC

The backquote kind  of warns that there will be  variables inside this
form, and the  coma kind of says  to not evaluate the  argument but to
put it as is.

So when we use it like this:

#+BEGIN_SRC lisp
(with-mocked-search-results
    (ok (with-output-to-string (out)
          (torrents "foo" out))
        "search ok"))
#+END_SRC

we can see how it gets expanded like this:

#+BEGIN_SRC lisp
    (macroexpand-1
     '(with-mocked-search-results ;; <-- note the quote
       (ok (with-output-to-string (out)
             (torrents "foo" out))
        "search ok"))
     )
  ;; (WITH-DYNAMIC-STUBS ((DEXADOR:GET HTMLPAGE)
  ;;                      (CL-TORRENTS::REQUEST-DETAILS RESULTPAGE))
  ;;    (OK (WITH-OUTPUT-TO-STRING (OUT) (TORRENTS "foo" OUT)) "search ok"))
  ;; T
#+END_SRC

Easy :)

** Conclusion

This leads us to the end of part one.

We now want or need more:

- getting more content (seeders, leechers)
- downloading the torrent file ?
- error handling (network errors or timeout, unexpected errors)
- scraping other sites, asynchronously  (the asynchronous part will be
  straightforward, there's  a library for  that and it's  one function
  change)
- some cache
- continuous integration,
- regular testing against the website,
- searching from a local Pirate Bay dump,
- sharing this program (standalone executable ? Roswell ?),
- some more functionnality (getting many magnet links at once)
- a command line tool ?
- …
